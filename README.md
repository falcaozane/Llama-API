Download the LLM from <br>
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/blob/main/llama-2-7b-chat.ggmlv3.q8_0.bin

create a folder in root directory "llama_model"
and save the LLM in this folder
<br>

1. run ingest.py
2. then python run.py
