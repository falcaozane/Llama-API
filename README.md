Download the LLM from <br>
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/blob/main/llama-2-7b-chat.ggmlv3.q8_0.bin


1. run ingest.py
2. then python run.py

<br/>
minimum 16gb RAM
